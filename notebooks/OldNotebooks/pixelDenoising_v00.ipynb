{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README from code source\n",
    "## NCS\n",
    "\n",
    "NCS is a Noise Correction Algorithm for sCMOS cameras.\n",
    "\n",
    "## Abstract\n",
    "Scientific CMOS (sCMOS) cameras are quickly gaining popularity in life sciences, material science and astronomy because its advantages in a much faster frame rate, larger field of view and higher detection efficiency than traditional cameras such as CCD and EMCCD. However, they introduce pixel-dependent noise that generates image artifacts and biases in quantification.\n",
    "\n",
    "NCS (noise correction algorithm for sCMOS (CMOS) cameras) is an algorithm that minimizes sCMOS noise from microscopy images with arbitrary structures. In the citation linked below, we show our new method enables significantly reduction of the pixel-dependent noises in fluorescence microscopy using a sCMOS camera and makes its performance approaching that of an ideal camera.\n",
    "\n",
    "## NCS source code demo\n",
    "The demo package consists of functions and scripts written in Python 3.6. The code was tested using Windows7. We recommend installing Anaconda with Python 3.6 and using the Spyder Python editor. This version of the demo code is a beta version. Future versions of the code will include more documentation.\n",
    "\n",
    "To run the demo code for simulated microtubule structure:\n",
    "\n",
    "\t1. Set the current folder in Spyder to NCS\\python3-6\n",
    "\t2. Open script NCSdemo_simulation.py. Set the value of the following parameters: imgsz (image size), Pixelsize, NA (numerical aperture of the objective), Lambda (emission wavelength), I (photon count of each fluorophore), bg (background photon count), N (number of  images), offset (offset ADU level of the sCMOS camera), iterationN (number of iterations), alpha (weight factor of noise contribution), Rs (size of segmented image) and the type of the OTF mask (default is OTFweighted).\n",
    "\t3. Run the code.\n",
    "\t4. The output includes: imsd (sCMOS image stack), out (the noise corrected image).\n",
    "\t5. The computation time depends on the imgsz (image size), N (number of images), iterationN (number of iterations) and Rs (segmentation size).\n",
    "\n",
    "### License and Citation\n",
    "NCS is released under the [GNU license](https://github.com/HuanglabPurdue/NCS/edit/master/LICENSE).\n",
    "\n",
    "Please cite NCS in your publications if it helps your research:\n",
    "\n",
    "  \t @article{Liu2017NCS,\n",
    "\tAuthor = {Liu, Sheng and Mlodzianoski1, Michael J. and Hu, Zhenhua and Ren, Yuan and McElmurry, Kristi and Suter, Daniel M. and Huang, Fang},\n",
    "\tJournal = {Nature Methods},\n",
    "\tTitle = {sCMOS noise-correction algorithm for microscopy images},\n",
    "\tYear = {2017}\n",
    "\tvolume = {14}\n",
    "\tnumber = {8}\n",
    "\tpages = {760-761}\n",
    "   }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel-wise denoising\n",
    "The algorithm is based on NCS (noise correction algorithm for sCMOS (scientific CMOS) cameras) at https://github.com/HuanglabPurdue/NCS\n",
    "\n",
    "The reference paper is as follow:\n",
    "https://www.nature.com/articles/nmeth.4379\n",
    "\n",
    "Some details of algorithms can be found at:\n",
    "1. Characterization of sCMOS camera: https://media.nature.com/original/nature-assets/nmeth/journal/v10/n7/extref/nmeth.2488-S1.pdf\n",
    "2. Algorithm details: https://media.nature.com/original/nature-assets/nmeth/journal/v14/n8/extref/nmeth.4379-S1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing diagram\n",
    "1. Correct offset and gain using pre-characterized values (some sCMOS camera manufacturers now provide these parameter maps) for each pixel to obtain a precorrected image ùê∑. Set all pixels with non-positive values in ùê∑ to a small but non-zero value such as $10^{-6}$, where $D_i =\\frac{A_i - o_i}{g_i}$, $A_i$ pixel intensity, $o_i$ pixel offset, $g_i$ pixel gain.\n",
    "2. Segment input image into sub-images with M by M pixels. The recommended value for M is 8~32.\n",
    "3. For each segment, obtain an estimate by minimizing a cost function $f = LLS + \\alpha\\sigma N$ where LLS and $\\sigma N$ stand for the simplified negative log-likelihood and the noise contribution near and outside the OTF periphery respectively, and **$\\alpha$ is an empirical weight factor** (a small $\\alpha$ results in a bad noise correction; a large \\alpha results in a decrease in resolution).\n",
    "4. For each segment, repeat step 3. All segments are independent and therefore can be processed in parallel through GPU or CPU. The regression converges within 20 iterations.\n",
    "\n",
    "![](nmeth.4379-S1.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "h5f = h5py.File('testing_file/TM0000000_CM0_CHN00.h5', 'r')\n",
    "imgStack = h5f['default'] # z, x, y\n",
    "plt.imshow(imgStack[0], cmap='gray')\n",
    "exImg = imgStack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "fish_path = os.path.abspath(os.path.join('..'))\n",
    "if fish_path not in sys.path:\n",
    "    sys.path.append(fish_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = 32 # size of segmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assuming \n",
    "imgsz = exImg.shape[0]# image size\n",
    "assert exImg.shape[0] == exImg.shape[1], 'Please crop the image to have the same pixels on x and y'\n",
    "# the number (imgsz/M)^2 small square patches will be processed in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterization of sCMOS camera\n",
    "\n",
    "## Offset and variance of sCMOS camera\n",
    "Offset values describe a constant level of ADUs (analog-to-digital unit) pre-engineered into the readout process in order to prevent negative ADUs caused by the readout noise. Both are estimated by performing temporally across M dark frames, e.g. $N = 60,000$. For pixel i\n",
    "\n",
    "offset: $o_i = \\frac{1}{N}\\sum_{n=1}^{N}s_i^n$\n",
    "\n",
    "variance: $v_i = \\frac{1}{N}\\sum_{n=1}^{N}(s_i^n)^2-o_i^2$\n",
    "\n",
    "## Gain of sCMOS camera\n",
    "To determine the gain value for each pixel the authors illuminated the camera with quasi-uniform stationary intensity patterns and recorded a series of image sequences (20,000 images in each sequence) at different average intensity levels ranging from ~20 to 200 photons per pixel (totally $K$ levels). **This is shot noise and estimated using Gaussian distribution which approximates the Poisson distribution**\n",
    "\n",
    "$\\hat{g_i} = \\arg \\min \\sum_{k=1}^K((v_i^k-v_i)-g_i(<D_i^k>-o_i))^2$\n",
    "\n",
    "where $<D_i^k>$ is mean ADU of all frames at level $k$, $v_i^k$ is the variance.\n",
    "\n",
    "Let $A_i$ is a vector $\\{(v_i^1 - v_i), \\cdots, (v_i^K - v_i)\\}$, and $B_i$ is a vector $\\{(<D_i^1> - o_i), \\cdots, (<D_i^K> - o_i)\\}$ and $\\hat{g_i} = (B_i B_i^T)^{-1}B_i A_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get offset matrix and variance matrix\n",
    "# from glob import glob\n",
    "# offset = []\n",
    "# var = []\n",
    "# for fname in glob('/Volumes/ahrenslab/davis/shared/for_ziqiang/blank_frame_mean_variance/t_*.npy'):\n",
    "#     print('loading file:' + fname)\n",
    "#     s_ = np.load(fname)\n",
    "#     offset.append(s_[0])\n",
    "#     var.append(s_[1])\n",
    "# offset = np.array(offset)\n",
    "# var = np.array(var)\n",
    "# offset_mat = offset.mean()\n",
    "# var_mat = var.mean() + offset.var()\n",
    "# gain_mat = np.ones(var_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# offset = np.load('offset_mat.npy')\n",
    "# var = np.load('var_mat.npy')\n",
    "# gain = np.load('gain_mat.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# offset plots, one can easily see some hotspots\n",
    "# plt.imshow(offset, cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute offset, variance, and gain matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "offsetMat = [];\n",
    "varmat = [];\n",
    "for nfile in sorted(glob('camera_statsgain_measure*.npz')):\n",
    "    print(nfile)\n",
    "    data = np.load(nfile)\n",
    "    tOff = data['arr_0']\n",
    "    tvar = data['arr_1']\n",
    "    offsetMat.append(tOff)\n",
    "    varmat.append(tvar)\n",
    "offsetMat = np.array(offsetMat)\n",
    "varmat = np.array(varmat)\n",
    "gainMatShape = (varmat.shape[1], varmat.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # sanity check if pure background is the same as 0mW\n",
    "# np.abs(offsetMat[0]-offset).mean()\n",
    "# np.abs(varmat[0]-var).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image to vector\n",
    "offsetVec = offsetMat.reshape(offsetMat.shape[0], -1)\n",
    "varVec = varmat.reshape(varmat.shape[0], -1)\n",
    "# remove 0mW (background)\n",
    "offsetVec = offsetVec - offsetVec[0]\n",
    "varVec = varVec - varVec[0]\n",
    "# remove 0mW\n",
    "offsetVec = offsetVec[1:]\n",
    "varVec = varVec[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gainVec = np.zeros(offsetVec.shape[1])\n",
    "for n in range(offsetVec.shape[1]):\n",
    "    noffset = offsetVec[:, n]\n",
    "    nvar = varVec[:, n]\n",
    "    gainVec[n] = np.inner(noffset, nvar)/ np.inner(noffset, noffset)\n",
    "    if np.sum(nvar<0)>0 or gainVec[0]<0:\n",
    "        gainVec[n] = 0\n",
    "\n",
    "offset = offsetMat[0]\n",
    "var = varmat[0]\n",
    "gain = np.array(gainVec).reshape(gainMatShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(gainVec, bins=1000, density=True, facecolor='g', alpha=0.75)\n",
    "plt.axis([0, 5, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pixel = 1000 #np.where(gainVec<0)[0][0]\n",
    "x = np.array([0, offsetVec[:, n_pixel].max()])\n",
    "y = x * gainVec[n_pixel]\n",
    "plt.scatter(offsetVec[:, n_pixel], varVec[:, n_pixel])\n",
    "plt.plot(x, y, '-r')\n",
    "plt.xlabel(r'$\\Delta$ offset')\n",
    "plt.ylabel(r'$\\Delta$ variance')\n",
    "plt.title('Pixel index %s'%(n_pixel))\n",
    "plt.axis([0, x.max()+1, 0, y.max()+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_ = np.sqrt(var)\n",
    "# plt.scatter(offset[np.logical_and(gain<10, gain>0)], var_[np.logical_and(gain<10, gain>0)],alpha =0.5)\n",
    "# plt.scatter(offset[gain>10], var_[gain>10],alpha =0.5)\n",
    "plt.scatter(offset[gain==0], var_[gain==0], alpha=0.5)\n",
    "plt.xlabel('offset')\n",
    "plt.ylabel('std')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "varVec[:, n_pixel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pixel = np.where(offset.reshape(-1) == offset.min())[0][0]\n",
    "x = np.array([0, offsetVec[:, n_pixel].max()])\n",
    "y = x * gainVec[n_pixel]\n",
    "plt.scatter(offsetVec[:, n_pixel], varVec[:, n_pixel])\n",
    "plt.plot(x, y, '-r')\n",
    "plt.xlabel(r'$\\Delta$ offset')\n",
    "plt.ylabel(r'$\\Delta$ variance')\n",
    "plt.title('Pixel index %s'%(n_pixel))\n",
    "plt.axis([0, offsetVec[:, n_pixel].max()+1, 0, varVec[:, n_pixel].max()+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_pixel = np.where(gain.reshape(-1) == gain[gain>0].min())[0][0]\n",
    "x = np.array([0, offsetVec[:, n_pixel].max()])\n",
    "y = x * gainVec[n_pixel]\n",
    "plt.scatter(offsetVec[:, n_pixel], varVec[:, n_pixel])\n",
    "plt.plot(x, y, '-r')\n",
    "plt.xlabel(r'$\\Delta$ offset')\n",
    "plt.ylabel(r'$\\Delta$ variance')\n",
    "plt.title('Pixel index %s'%(n_pixel))\n",
    "plt.axis([0, offsetVec[:, n_pixel].max()+1, 0, varVec[:, n_pixel].max()+1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exImg = imgStack[0]\n",
    "imgD = (exImg - offset) / (gain + 1e-12)\n",
    "imgD[gain < 0.5] = 1e-6\n",
    "# imgD[gain > 10] = 1e-6\n",
    "imgD[imgD <= 0] = 1e-6\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(exImg, cmap='gray')\n",
    "ax1.set_title('Raw image')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(imgD, cmap='gray')\n",
    "ax2.set_title('Preprocessed')\n",
    "ax2.axis('off')\n",
    "f.savefig('comparison.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "imgD = (exImg - offset) / (gain + 1e-12)\n",
    "imgD[gain < 0.5] = 1e-6\n",
    "# imgD[gain > 10] = 1e-6\n",
    "imgD[imgD <= 0] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.hist(exImg.reshape(-1), 100, density=True)\n",
    "ax1.set_title('Raw image')\n",
    "ax2.hist(imgD.reshape(-1), 100, density=True)\n",
    "ax2.set_title('Preprocessed')\n",
    "f.savefig('comparison_hist.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from simpleDenioseTool import simpleDN\n",
    "imgD_ = simpleDN(exImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTF\n",
    "A diffraction limited imaging system has a cutoff frequency above which the higher frequency signal cannot be collected. The cutoff frequency is defined by the numerical aperture (NA), and the detection wavelength ($\\lambda$), of the imaging system. The athors used this cutoff frequency to extract the noise part of the image. Aberrations in the microscope system might decrease the cutoff frequency which makes the use of theoretical cutoff a conservative approach. In the 2D Fourier transform of a microscopy image, the signal from the diffraction limited system is only contained in a circular region defined by the optical transfer function (OTF) of the imaging system. The OTF is the autocorrelation of the pupil function of the imaging system. For an ideal imaging system, the pupil radius is $\\frac{NA}{\\lambda}$, and the OTF radius is therefore two times of this quantity, $2\\frac{NA}{\\lambda}$.\n",
    "\n",
    "noise contribution in 2D transformed image $U$ is calculated as\n",
    "\n",
    "$\\sigma = \\sum_{k_x, k_y}|U(k_x, k_y)M(k_x, k_y)|$\n",
    "\n",
    "## Parameters\n",
    "* NA: numerical aperture of the objective\n",
    "* $\\lambda$: emission wavelength (micro-meter, um)\n",
    "* $\\Delta x = \\Delta y$: pixel size (um) of the image in two dimensions, these are used to compute the 2D transform of the image, u(x, y) with L by L pixels as $U(k_x, k_y) = \\frac{1}{L}\\sum_x\\sum_y u(x, y) \\exp(-i2\\pi k_x x)\\exp(-i2\\pi k_y y)$\n",
    "\n",
    "## OTF mask\n",
    "The OTF mask is implemented using a raised cosine filter defined by two parameters $\\beta$ and $T$. \n",
    "\n",
    "$M(k_x, k_y) = 1$ if $k_r = \\sqrt{k_x^2 + k_y^2}>\\frac{1+\\beta}{2T}$\n",
    "\n",
    "$M(k_x, k_y) = 0$ if $k_r < \\frac{1-\\beta}{2T}$\n",
    "\n",
    "$M(k_x, k_y) = \\frac{1}{2} + \\frac{1}{2}\\cos[\\frac{\\pi T}{\\beta}(k_r - \\frac{1-\\beta}{2T})]$ if otherwise\n",
    "\n",
    "One can use one of the follow OTF masks:\n",
    "1. OTF weighted mask (**default**; better peformance in denoising, but signal would be decreased, comparin to noise-only mask) $\\beta = 1$, $T = \\frac{\\lambda}{4NA*1.4}$, \n",
    "2. Noise-only mask: $\\beta = 0.2$, $T = \\frac{(1-\\beta)\\lambda}{4NA}$, \n",
    "3. An adjustable version of weighted mask Ôºàusing additional parameters like $w$ and $h$Ôºâ: $\\beta = \\pi/2*\\frac{k_{max}/w_0-1}{\\arccos(1-2*h)+\\pi/2*(k_{max}/w_0-1)}$, $T = \\frac{1-\\beta}{2w_0}$, $w_0 = w*\\frac{NA}{\\lambda}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pixelsize = 6.5 # pixel size is the property of the camera (make sure this value is correct)\n",
    "# Magnification = 16\n",
    "# Pixelsize = Pixelsize / Magnification\n",
    "# NA = 0.8 # numerical aperture of the objective\n",
    "# # emission should be changed according to the real experiment\n",
    "# Lambda = 0.500 # emission wavelength\n",
    "# w=1 # parameter for adjusted OTF\n",
    "# h=0.7 # parameter for adjusted OTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pixelwiseDenoising.denoisetools as ncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #OTF filter\n",
    "# OTFfilter = ncs.genfilter(M,Pixelsize,NA,Lambda,Type='OTFweighted',w=1,h=0.7)\n",
    "# plt.imshow(OTFfilter, cmap = plt.cm.gray)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(offset.reshape(-1), np.sqrt(var.reshape(-1)))\n",
    "# plt.xlabel(\"Offset\")\n",
    "# plt.ylabel(\"Std.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # preprocessing of image\n",
    "# imgD = (imgStack[0]-offset)/gain\n",
    "# imgD[gain<0] = 1e-6\n",
    "# imgD[imgD<=0] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # crop image\n",
    "# imgD_ = imgD[512:1024, 512:1024]\n",
    "# gain_ = gain[512:1024, 512:1024]\n",
    "# gain_[gain_ < 0] = 1e-6\n",
    "# var_ = var[512:1024, 512:1024]\n",
    "\n",
    "# # imgD_ = imgD\n",
    "# # imgD_[imgD_ < 0] = 1e-6\n",
    "# # gain_ = gain\n",
    "# # var_ = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alpha = 0.1 # weight factor of noise correction contribution vs LLS (simplified negative log likelihood function)\n",
    "# iterationN = 15 # number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # optical transfer function filter is defined using filter type (default is OTFweighted), w and h\n",
    "# out = ncs.reducenoise(M, imgD_,var_,gain_,Pixelsize,NA,Lambda,alpha,iterationN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out[gain_<0] = 1e-6\n",
    "# out_ = out\n",
    "# out_[gain_<0.5] = 1e-6\n",
    "# imgD_[gain_<0.5] = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "# ax1.imshow(imgStack[0][512:1024, 512:1024], cmap='gray')\n",
    "# # ax1.imshow(imgStack[0], cmap='gray')\n",
    "# ax1.set_title('Raw image')\n",
    "# ax1.axis('off')\n",
    "# ax2.imshow(imgD_, cmap='gray')\n",
    "# ax2.set_title('Preprocessed')\n",
    "# ax2.axis('off')\n",
    "# ax3.imshow(out_, cmap='gray')\n",
    "# ax3.set_title('Denoised image')\n",
    "# ax3.axis('off')\n",
    "# f.savefig('comparison.png', dpi=1000)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for alpha in [0, 0.1, 0.9, 9]:\n",
    "#     out = ncs.reducenoise(M, imgD_,var_,gain_,Pixelsize,NA,Lambda,alpha,iterationN)\n",
    "#     out[gain_<0] = 1e-6\n",
    "#     out_ = out\n",
    "#     out_[gain_<0.5] = 1e-6\n",
    "#     plt.imshow(out_, cmap='gray')\n",
    "#     plt.title(r'$\\alpha$ = %0.1f'%alpha)\n",
    "#     plt.show()\n",
    "#     diff = np.abs(out_ - imgD_)/imgD_\n",
    "#     print(diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is the denoised image compared to the one with preprocessing?\n",
    "\n",
    "### Preprocessing imaging is defined as D\n",
    "\n",
    "$D_i = (I_i - o_i)/\\hat{g}_i$\n",
    "\n",
    "### Comparison\n",
    "\n",
    "1. compare the accumulated distribution between denoised image vs preprocessing image -- it has a visual difference at value ranged from 10 to 30\n",
    "\n",
    "2. compare the relative change between denoised image vs preprocessing image at range from 10 to 30 -- relative change is defined as $|D_i - \\hat{D}_i|/D_i$, which is quite small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out__ = out_[imgD_ > 0]\n",
    "# imgD__ = imgD_[imgD_ > 0]\n",
    "# values, base = np.histogram(out__, bins=1000)\n",
    "# #evaluate the cumulative\n",
    "# cumulative = np.cumsum(values)/len(out__)\n",
    "# # plot the cumulative function\n",
    "# plt.plot(base[:-1], cumulative, c='blue',label='denoised')\n",
    "# values, base = np.histogram(imgD__, bins=1000)\n",
    "# #evaluate the cumulative\n",
    "# cumulative = np.cumsum(values)/len(imgD__)\n",
    "# # plot the cumulative function\n",
    "# plt.plot(base[:-1], cumulative, c='red',label='preprocessing')\n",
    "# plt.xlabel('corrected pixel value')\n",
    "# plt.ylabel('accumulated frac.')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diff_ = diff[np.logical_and(imgD_ > 10, imgD_<30)]\n",
    "# _, _, _ = plt.hist(diff_, 1000)\n",
    "# plt.ylabel('counts')\n",
    "# plt.xlabel('relative change')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

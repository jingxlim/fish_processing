{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image registration\n",
    "\n",
    "https://en.wikipedia.org/wiki/Image_registration\n",
    "\n",
    "1. Intensity-based vs feature based\n",
    "    1. Intensity-based: compare intensity patterns in images via correlation metrics\n",
    "    2. feature-based: find correspondence between image features such as points, lines, and contours\n",
    "2. **Transformation models**\n",
    "    1. Linear -- Affine transform\n",
    "    2. Elastic or nonrigid -- locally wrapping methods\n",
    "    3. Diffeomorphic mapping -- LDDMM (Large deformation diffeomorphic metric mapping, https://en.wikipedia.org/wiki/Large_deformation_diffeomorphic_metric_mapping)\n",
    "3. Spatial and frequency domain methods (phase correlation)\n",
    "4. Single- vs multi-modality (imaging from different sources)\n",
    "\n",
    "### Optimization -- Similarity measures for image registration\n",
    "\n",
    "1. Mean square difference (intensity difference)\n",
    "2. Mutual information (or nomalized mutual information) -- most popular one\n",
    "3. Cross-correlation -- more computationally intensive than MI, can be useful for fine-scale nonlinear registration step\n",
    "4. Ratio image uniformity (this could be useful while images from different imaging modality)\n",
    "5. Landmark guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-modal registration\n",
    "\n",
    "### Linear transform\n",
    "Y = T X + b\n",
    "### Rigid body transform\n",
    "Rotation and translation.\n",
    "### Affine transform\n",
    "Rotation, translation, scaling and shears.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ants code\n",
    "```bash\n",
    "antsRegistration --dimensionality 3 --float 0 \\  \n",
    "        --output [$thisfolder/pennTemplate_to_${sub}_,$thisfolder/pennTemplate_to_${sub}_Warped.nii.gz] \\  \n",
    "        --interpolation Linear \\  \n",
    "        --winsorize-image-intensities [0.005,0.995] \\  # remove hot spots -- preprocessing\n",
    "        --use-histogram-matching 0 \\  # ajust the images with the same constrast -- preprocessing\n",
    "        --initial-moving-transform [$t1brain,$template,1] \\   \n",
    "        --transform Affine[0.1] \\  # 0.1 gradient descent step -- this is done using L-BFGS-B in dipy\n",
    "        --metric MI[$t1brain,$template,1,32,Regular,0.25] \\  # parameters are [fixed, moving, weight, bins, sampling, samplingPercentage]\n",
    "        --convergence [1000x500x250x100,1e-6,10] \\  # run 4 levels (or multi-resolution steps) with a maximum number of iterations of 1000,500,250,100. The threshold (1e-6) tells the algorithm to stop if the improvement in mutual information has not changed more than 1e-6 in the last 10 iterations  -- this is done using L-BFGS-B in dipy\n",
    "        --shrink-factors 8x4x2x1 \\  # the 4 hierarchical steps will have resolutions divided by 8,4,2,1\n",
    "        --smoothing-sigmas 3x2x1x0vox #  smoothing values for each step: sigma 3,2,1,0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dipy.align.transforms import TranslationTransform2D, TranslationTransform3D, RigidTransform2D, RigidTransform3D, AffineTransform2D, AffineTransform3D\n",
    "from dipy.align.imaffine import MutualInformationMetric, AffineRegistration\n",
    "\n",
    "def estimate_affine(fixed, moving, trans_key = 'rigid'):\n",
    "    assert len(moving.shape) == len(fixed.shape)\n",
    "    if len(moving.shape) == 2:\n",
    "        translation = TranslationTransform2D()\n",
    "        rigid = RigidTransform2D()\n",
    "        affine = AffineTransform2D()\n",
    "    elif len(moving.shape) == 3:\n",
    "        translation = TranslationTransform3D()\n",
    "        rigid = RigidTransform3D()\n",
    "        affine = AffineTransform3D()\n",
    "    \n",
    "    nbins = 32\n",
    "    sampling_prop = .25\n",
    "    metric = MutualInformationMetric(nbins, sampling_prop) #MI\n",
    "    level_iters = [1000, 500, 250, 125]\n",
    "    factors = [8, 4, 2, 1]\n",
    "    sigmas = [3.0, 2.0, 1.0, 0.0]\n",
    "    # method could be CG, BFGS, Newton-CG, dogleg or trust-ncg\n",
    "\n",
    "    params0 = None\n",
    "    \n",
    "    affmap = AffineRegistration(metric=metric, level_iters=level_iters, sigmas=sigmas, \n",
    "                                factors=factors, method='L-BFGS-B', ss_sigma_factor=None, \n",
    "                                options=None, verbosity=0)\n",
    "    tx_tr = affmap.optimize(fixed, moving, translation, params0)\n",
    "    if trans_key == 'translation':\n",
    "        tx = tx_tr\n",
    "    elif trans_key == 'rigid':\n",
    "        tx = affmap.optimize(fixed, moving, rigid, params0, starting_affine = tx_tr.affine)\n",
    "    elif trans_key == 'affine':\n",
    "        tx = affmap.optimize(fixed, moving, rigid, params0, starting_affine = tx_tr.affine)\n",
    "        tx = affmap.optimize(fixed, moving, affine, params0, starting_affine = tx.affine)\n",
    "    \n",
    "    return tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "\n",
    "move = imread('move.tif', as_grey=True)\n",
    "fix = imread('fix.tif', as_grey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(fix, cmap='gray')\n",
    "ax1.set_title('Fix image')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(move, cmap='gray')\n",
    "ax2.set_title('Moved image')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out_affine = estimate_affine(fix, move, trans_key ='rigid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dipy.io as dipyio\n",
    "dipyio.save_pickle('affine', out_affine)\n",
    "out_ = dipyio.load_pickle('affine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_ = out_.transform(move)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(fix, cmap='gray')\n",
    "ax1.set_title('Fix image')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(warped_, cmap='gray')\n",
    "ax2.set_title('Affined moved image')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-modal registration\n",
    "\n",
    "### Nonliear transform -- Large deformation diffeomorphic metric mapping (LDDMM)\n",
    "\n",
    "Image I is a diffeomorphism of template image $I_{tmp}$ as $\\psi: I_{tmp} \\rightarrow I$ and $\\psi \\in Diff_v$, and $I = I_{tmp} \\circ \\psi$ ($\\circ$ elementwise multiplication).\n",
    "\n",
    "The diffeomorphisms are generated via smooth flows $\\phi_t$ ($t\\in[0,1]$), $\\psi = \\phi_1$ satisfying the  Lagrangian and Eulerian specification of the flow field associated to the ordinary differential equation, $\\frac{d}{dt}\\phi_t = v_t \\circ \\phi_t$ and $\\phi_0 = id$\n",
    "\n",
    "![](ant-syn.png)\n",
    "\n",
    "1. First term (in blue): smoothness term (or diffeomorphic regularization) -- Minimize a smooth velocity field: the geodesic path between two images. L is a smoothing operator, v is a transform (velocity field), t is time.\n",
    "2. Second term (rest): similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## live registration\n",
    "```bash\n",
    "antsRegistration -d 3 –float 1 -o [fish1 , fish1 Warped.nii.gz] \\\n",
    "                 --interpolation WelchWindowedSinc \\\n",
    "                 --use-histogram-matching 0 \\\n",
    "                 -r [ref/vglut-ref.nii, fish1–01.nii.gz,1] \\\n",
    "                 -t rigid[0.1]\\\n",
    "                 -m MI[ref/vglut-ref.nii, fish1–01.nii.gz,1,32, Regular,0.25]\\\n",
    "                 -c [200x200x200x0,1e-8,10]\\ \n",
    "                 --shrink-factors 12x8x4x2\\\n",
    "                 --smoothing-sigmas 4x3x2x1vox\\\n",
    "                 -t Affine[0.1]\n",
    "                 -m MI[ref/vglut-ref.nii, fish1–01.nii.gz,1,32, Regular,0.25]\n",
    "                 -c [200x200x200x0,1e-8,10]\n",
    "                 --shrink-factors 12x8x4x2\n",
    "                 --smoothing-sigmas 4x3x2x1vox\n",
    "                 -t SyN[0.05,6,0.5]\n",
    "                 -m CC[ref/vglut-ref.nii, fish1–01.nii.gz,1,2]\n",
    "                 -c [200x200x200x200x10,1e-7,10]\n",
    "                 --shrink-factors 12x8x4x2x1\n",
    "                 --smoothing-sigmas 4x3x2x1x0vox\n",
    "\n",
    "```\n",
    "\n",
    "float : 0 (double), 1 (float)\n",
    "interpolation: Several interpolation options are available in ITK. These have all been made available. Currently the interpolator choice is only used to warp (and possibly inverse warp) the final output image(s).\n",
    "\n",
    "## fixed registration\n",
    "for Syn using parameters[0.1,6,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "h5f = h5py.File('../pixelwiseDenoising/testing_file/TM0000000_CM0_CHN00.h5', 'r')\n",
    "imgStack = h5f['default'] # z, x, y\n",
    "plt.imshow(imgStack[0], cmap='gray')\n",
    "exImg = imgStack[:, 1024:2048, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imsave\n",
    "imsave('gfap-gcamps.tif', exImg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image registration\n",
    "\n",
    "https://en.wikipedia.org/wiki/Image_registration\n",
    "\n",
    "1. Intensity-based vs feature based\n",
    "    1. Intensity-based: compare intensity patterns in images via correlation metrics\n",
    "    2. feature-based: find correspondence between image features such as points, lines, and contours\n",
    "2. **Transformation models**\n",
    "    1. Linear -- Affine transform\n",
    "    2. Elastic or nonrigid -- locally wrapping methods\n",
    "    3. Diffeomorphic mapping -- LDDMM (Large deformation diffeomorphic metric mapping, https://en.wikipedia.org/wiki/Large_deformation_diffeomorphic_metric_mapping)\n",
    "3. Spatial and frequency domain methods (phase correlation)\n",
    "4. Single- vs multi-modality (imaging from different sources)\n",
    "\n",
    "### Optimization -- Similarity measures for image registration\n",
    "\n",
    "1. Mean square difference (intensity difference)\n",
    "2. Mutual information (or nomalized mutual information) -- most popular one\n",
    "3. Cross-correlation -- more computationally intensive than MI, can be useful for fine-scale nonlinear registration step\n",
    "4. Ratio image uniformity (this could be useful while images from different imaging modality)\n",
    "5. Landmark guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-modal registration\n",
    "\n",
    "### Linear transform\n",
    "Y = T X + b\n",
    "### Rigid body transform\n",
    "Rotation and translation.\n",
    "### Affine transform (Unnecessary)\n",
    "Rotation, translation, scaling and shears.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ants code\n",
    "```bash\n",
    "antsRegistration --dimensionality 3 --float 0 \\  \n",
    "        --output [$thisfolder/pennTemplate_to_${sub}_,$thisfolder/pennTemplate_to_${sub}_Warped.nii.gz] \\  \n",
    "        --interpolation Linear \\  \n",
    "        --winsorize-image-intensities [0.005,0.995] \\  # remove hot spots -- preprocessing\n",
    "        --use-histogram-matching 0 \\  # ajust the images with the same constrast -- preprocessing\n",
    "        --initial-moving-transform [$t1brain,$template,1] \\   \n",
    "        --transform Affine[0.1] \\  # 0.1 gradient descent step -- this is done using L-BFGS-B in dipy\n",
    "        --metric MI[$t1brain,$template,1,32,Regular,0.25] \\  # parameters are [fixed, moving, weight, bins, sampling, samplingPercentage]\n",
    "        --convergence [1000x500x250x100,1e-6,10] \\  # run 4 levels (or multi-resolution steps) with a maximum number of iterations of 1000,500,250,100. The threshold (1e-6) tells the algorithm to stop if the improvement in mutual information has not changed more than 1e-6 in the last 10 iterations  -- this is done using L-BFGS-B in dipy\n",
    "        --shrink-factors 8x4x2x1 \\  # the 4 hierarchical steps will have resolutions divided by 8,4,2,1\n",
    "        --smoothing-sigmas 3x2x1x0vox #  smoothing values for each step: sigma 3,2,1,0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import h5py\n",
    "# h5f = h5py.File('../pixelwiseDenoising/testing_file/TM0000000_CM0_CHN00.h5', 'r')\n",
    "# imgStack = h5f['default'] # z, x, y\n",
    "# plt.imshow(imgStack[0], cmap='gray')\n",
    "# fix = imgStack[0]\n",
    "# np.save('fix', fix)\n",
    "# fix = np.load('fix.npy')\n",
    "# plt.imshow(fix, cmap='gray')\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os, sys\n",
    "# fish_path = os.path.abspath(os.path.join('..'))\n",
    "# if fish_path not in sys.path:\n",
    "#     sys.path.append(fish_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pixelwiseDenoising.simpleDenioseTool import simpleDN\n",
    "# fix = simpleDN(fix, '../pixelwiseDenoising/gainMat20180208')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = tf.AffineTransform(translation=(50, 50), rotation=-np.pi/30)\n",
    "move = tf.warp(fix, tform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(fix, cmap='gray')\n",
    "ax1.set_title('Fix image')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(move, cmap='gray')\n",
    "ax2.set_title('Moved image')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from affine import estimate_translation, estimate_rigid, estimate_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter ss_sigma_factor (Scale space sigma-factor ratio)\n",
    "\n",
    "The scale space is a list of images produced by smoothing the input image with a Gaussian kernel with increasing smoothing parameter. If the image’s voxels are isotropic, the smoothing will be the same along all directions: at level L = 0, 1, ...; the sigma is given by s∗$(2^L−1)$. If the voxel dimensions are not isotropic, then the smoothing is weaker along low resolution directions. This is good for z stack is much less than x, y dimensions. By default, **factor** and **sigma** are given as list with same length, or using **ss_sigma_factor=0.2** instead with given level (decided by parameter **level_iters**)\n",
    "\n",
    "By default\n",
    "```python\n",
    "level_iters = [1000, 500, 250, 125]\n",
    "factors = [8, 4, 2, 1]\n",
    "sigmas = [3.0, 2.0, 1.0, 0.0]\n",
    "ss_sigma_factor=None\n",
    "```\n",
    "\n",
    "### Translation\n",
    "```python\n",
    "tform = tf.AffineTransform(translation=(50, 50), rotation=0)\n",
    "```\n",
    "> CPU times: user 2.69 s, sys: 384 ms, total: 3.08 s, Wall time: 2.93 s\n",
    "\n",
    "### Rigid\n",
    "```python\n",
    "tform = tf.AffineTransform(translation=(50, 50), rotation=-np.pi/30)\n",
    "trans_key ='rigid'\n",
    "```\n",
    "> CPU times: CPU times: user 30.9 s, sys: 1.39 s, total: 32.3 s, Wall time: 30.4 s\n",
    "```python\n",
    "tform = tf.AffineTransform(translation=(50, 50), rotation=-np.pi/30)\n",
    "trans_key ='affine'\n",
    "```\n",
    "> CPU times: user 1min 5s, sys: 2.17 s, total: 1min 7s, Wall time: 1min 4s\n",
    "\n",
    "### Performance is measued using comparison of the optimized transform to the known inverse transform\n",
    "see test code below\n",
    "1. affine is not necessary for this task.\n",
    "\n",
    "### 3d Rigid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out_affine = estimate_affine(fix, move, ss_sigma_factor=1.0, level_iters=[10000, 1000, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_ = out_affine.transform(move)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(fix, cmap='gray')\n",
    "ax1.set_title('Fix image')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(warped_, cmap='gray')\n",
    "ax2.set_title('Affined moved image')\n",
    "ax2.axis('off')\n",
    "plt.show()\n",
    "plt.imshow((fix-fix.mean())/fix.var() - (warped_-warped_.mean())/warped_.var())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of the results with know reverse of rotations\n",
    "rotationMat = tf.warp(np.ones(fix.shape), tform)\n",
    "inv_tform = tf.AffineTransform(translation=(-50, -50), rotation=np.pi/30)\n",
    "raw = tf.warp(rotationMat, inv_tform)\n",
    "\n",
    "transformRot = out_affine.transform(rotationMat)\n",
    "plt.imshow(raw-transformRot)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inter-modal registration\n",
    "\n",
    "### Nonliear transform -- Large deformation diffeomorphic metric mapping (LDDMM)\n",
    "\n",
    "Image I is a diffeomorphism of template image $I_{tmp}$ as $\\psi: I_{tmp} \\rightarrow I$ and $\\psi \\in Diff_v$, and $I = I_{tmp} \\circ \\psi$ ($\\circ$ elementwise multiplication).\n",
    "\n",
    "The diffeomorphisms are generated via smooth flows $\\phi_t$ ($t\\in[0,1]$), $\\psi = \\phi_1$ satisfying the  Lagrangian and Eulerian specification of the flow field associated to the ordinary differential equation, $\\frac{d}{dt}\\phi_t = v_t \\circ \\phi_t$ and $\\phi_0 = id$\n",
    "\n",
    "![](ant-syn.png)\n",
    "\n",
    "1. First term (in blue): smoothness term (or diffeomorphic regularization) -- Minimize a smooth velocity field: the geodesic path between two images. L is a smoothing operator, v is a transform (velocity field), t is time.\n",
    "2. Second term (rest): similarity metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## live registration\n",
    "```bash\n",
    "antsRegistration -d 3 –float 1 -o [fish1 , fish1 Warped.nii.gz] \\\n",
    "                 --interpolation WelchWindowedSinc \\\n",
    "                 --use-histogram-matching 0 \\\n",
    "                 -r [ref/vglut-ref.nii, fish1–01.nii.gz,1] \\\n",
    "                 -t rigid[0.1]\\\n",
    "                 -m MI[ref/vglut-ref.nii, fish1–01.nii.gz,1,32, Regular,0.25]\\\n",
    "                 -c [200x200x200x0,1e-8,10]\\ \n",
    "                 --shrink-factors 12x8x4x2\\\n",
    "                 --smoothing-sigmas 4x3x2x1vox\\\n",
    "                 -t Affine[0.1]\n",
    "                 -m MI[ref/vglut-ref.nii, fish1–01.nii.gz,1,32, Regular,0.25]\n",
    "                 -c [200x200x200x0,1e-8,10]\n",
    "                 --shrink-factors 12x8x4x2\n",
    "                 --smoothing-sigmas 4x3x2x1vox\n",
    "                 -t SyN[0.05,6,0.5]\n",
    "                 -m CC[ref/vglut-ref.nii, fish1–01.nii.gz,1,2]\n",
    "                 -c [200x200x200x200x10,1e-7,10]\n",
    "                 --shrink-factors 12x8x4x2x1\n",
    "                 --smoothing-sigmas 4x3x2x1x0vox\n",
    "\n",
    "```\n",
    "\n",
    "float : 0 (double), 1 (float)\n",
    "interpolation: Several interpolation options are available in ITK. These have all been made available. Currently the interpolator choice is only used to warp (and possibly inverse warp) the final output image(s).\n",
    "\n",
    "## fixed registration\n",
    "for Syn using parameters[0.1,6,0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
